{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# To get started with Data Understanding:\n",
        ">Kaggle Link:\n",
        "https://www.kaggle.com/competitions/higgs-boson/data\n",
        ">\n",
        ">Journal Article about the dataset (*Documentation about this data is good.*):\n",
        "https://proceedings.mlr.press/v42/cowa14.pdf\n",
        ">\n",
        ">Offical dataset (*if you don't want to use Kaggle*):\n",
        "https://opendata.cern.ch/record/328\n",
        "\n",
        "Type this into your notebook:\n",
        ">>`!curl -O https://opendata.cern.ch/record/328/files/atlas-higgs-challenge-2014-v2.csv.gz`\n",
        ">>\n",
        ">>`!ls`\n",
        ">>\n",
        ">>`!gunzip 'atlas-higgs-challenge-2014-v2.csv.gz'`\n"
      ],
      "metadata": {
        "id": "koRwh33071Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O -k https://opendata.cern.ch/record/328/files/atlas-higgs-challenge-2014-v2.csv.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF7EONAU27Rw",
        "outputId": "4c88cf15-0770-413b-eaab-11121153aa4c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 62.5M  100 62.5M    0     0  5313k      0  0:00:12  0:00:12 --:--:-- 8645k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls # sanity check."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xfgSkH18InN",
        "outputId": "7f69bfad-0deb-425d-f753-2315b8456636"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "atlas-higgs-challenge-2014-v2.csv.gz  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip 'atlas-higgs-challenge-2014-v2.csv.gz'"
      ],
      "metadata": {
        "id": "C8ktn7kJ8MSv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls # sanity check."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7Y18wV78U4f",
        "outputId": "2e459eea-7578-4158-c6e2-42c1aa5d229f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "atlas-higgs-challenge-2014-v2.csv  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "YY0OGjs48WS1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('atlas-higgs-challenge-2014-v2.csv')\n",
        "df.drop(['KaggleSet', 'KaggleWeight', 'EventId', 'Weight'], axis=1, inplace=True) # drop columns that we do not need to feed into our model."
      ],
      "metadata": {
        "id": "uQvzKZL99tUB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.columns) # The 31st var is 'Label', which we will need in order to know what rows are sig/bkg."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K8MjYdjdyt2",
        "outputId": "5c6eb1fb-9b30-4dae-e3aa-f7d2488db45c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I looped through the dataframe columns to get:\n",
        "> #### `VarNames`, which has all the **RAW + FEATURE** variables.\n",
        "> #### `RawNames`, which has all the **PRI/RAW** feature variables.\n",
        "> #### `FeatureNames`, which has all the **DER/FEATURE** variables."
      ],
      "metadata": {
        "id": "rXH30F5CYA2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VarNames=list(df.columns) # All the variables in the dataset.\n",
        "RawNames=list() # Variables classified as 'RAW'.\n",
        "FeatureNames=list() # Variables derived from 'RAW'.\n",
        "for col in df.columns:\n",
        "  if col == 'Label':\n",
        "    continue # skipping sig/bkg.\n",
        "  if 'PRI' in col:\n",
        "    RawNames.append(col)\n",
        "  elif 'DER' in col:\n",
        "    FeatureNames.append(col)\n",
        "# Note: After reading the article, \"The subject of the Challenge\n",
        "# was to study the H to tau tau channel.\"\n",
        "# So maybe we only test ['DER_pt_h','DER_deltar_tau_lep','DER_pt_ratio_lep_tau','PRI_tau_pt','PRI_tau_eta','PRI_tau_phi']?"
      ],
      "metadata": {
        "id": "OWMDkIqm2VzS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So now, we have lists that seperate the raw variables, and feature variables.\n",
        "print(VarNames)\n",
        "print(RawNames)\n",
        "print(FeatureNames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOqxqiXadHy1",
        "outputId": "92574ad9-c1fe-4378-e13d-a66b07408c9a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality', 'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta', 'PRI_tau_phi', 'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi', 'PRI_met', 'PRI_met_phi', 'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi', 'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_all_pt', 'Label']\n",
            "['PRI_tau_pt', 'PRI_tau_eta', 'PRI_tau_phi', 'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi', 'PRI_met', 'PRI_met_phi', 'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi', 'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_all_pt']\n",
            "['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality', 'DER_lep_eta_centrality']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### By running this code, we can identify where to start our filtering for signal and background"
      ],
      "metadata": {
        "id": "LIubD7bGTFmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.Label.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_x5j_KmSzvq",
        "outputId": "1d6710c4-8826-47eb-b5c5-bcfdf8620b23"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['s', 'b'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import necessary ML libraries."
      ],
      "metadata": {
        "id": "ysvQMLVzt3lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from IPython.display import Image\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Sequential #keras.Sequential([])\n",
        "from tensorflow.keras.layers import Dense #layers.Dense()\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "z6dpECaGTwT1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(df)\n",
        "print(\"sample size: \", n)\n",
        "print(\"80% of total data: \", int(n*.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gttU3RinjlxM",
        "outputId": "9b818ca6-4b31-4bbd-b87f-e6efa26124e9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample size:  818238\n",
            "80% of total data:  654590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#n = len(df) # sample size.\n",
        "#Train_sample=df[:int(n * .8)] # training sample size.\n",
        "#Test_sample=df[int(n * .8):] # testing sample size.\n",
        "\n",
        "#X_Train=np.array(Train_sample[VarNames[:-1]]) # EXPLANATORY training sample of every feature (except Label).\n",
        "#y_Train=np.array(Train_sample.Label=='s') # RESPONSE training sample of signal.\n",
        "\n",
        "#X_Test=np.array(Test_sample[VarNames[:-1]]) # EXPLANATORY testing sample of every feature (except Label).\n",
        "#y_Test=np.array(Test_sample.Label=='s') # RESPONSE testing sample of signal."
      ],
      "metadata": {
        "id": "d-Z7Dk7zWX-f"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This might be better for making data a SRS.\n",
        "X = df[VarNames[:-1]].values\n",
        "y = (df.Label == 's').astype(int).values\n",
        "\n",
        "X_Train, X_Test, y_Train, y_Test = train_test_split(\n",
        "    X,y, test_size=.2, random_state=32, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "nZEkR4BAlIlj"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}